{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b088396",
   "metadata": {},
   "source": [
    "# WEB SCRAPING ASSIGNMENT-2 -----> SELENIUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f5338ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import alll reqired libraries\n",
    "import selenium                  #library to work with selenium\n",
    "import pandas as pd              # library to make dataframe\n",
    "from selenium import webdriver   # import webdriver module fromv selelnium to open up automated chrome window\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore any sort of warnings\n",
    "import time                      # to stop search engine for few seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b6fb3",
   "metadata": {},
   "source": [
    "======================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10a64e",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for ‚ÄúData Analyst‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed216f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver1 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4581371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up naukri.com website on automated chrome window\n",
    "driver1.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6202fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for job search bar\n",
    "search_field_designation1=driver1.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_designation1.send_keys('Data analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b24bc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location in location bar\n",
    "search_field_loc1=driver1.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "search_field_loc1.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a586ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search button\n",
    "search_button1=driver1.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div[1]/div[6]\")\n",
    "search_button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ded71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we will scrape all the tags where we have job titles\n",
    "title_tags1=driver1.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_titles1=[]  # creating empty list\n",
    "for i in title_tags1: # iterating over each web element of tittle\n",
    "    job_titles1.append(i.text) #adding values to the list\n",
    "Job_title1=job_titles1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b6f1de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#firts we will scrape all the tags where we have company names\n",
    "company_tags1=driver1.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "company_names1=[]  # creating empty list\n",
    "for c in company_tags1:  # iterating over each web element of company name\n",
    "    company_names1.append(c.text) #adding data to the list\n",
    "company_name1=company_names1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df2f57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job location tags\n",
    "location_tags1=driver1.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]')\n",
    "location_list1=[]  # creating empty  list\n",
    "for l in location_tags1:    ## iterating over each web element of location\n",
    "    location_list1.append(l.text)  # adding data to the list\n",
    "location1=location_list1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99ab521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping experience tags\n",
    "experience_tags1=driver1.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')\n",
    "experience_list1=[]   # creating empty list\n",
    "for e in experience_tags1:  # iterating over each web element of experience\n",
    "    experience_list1.append(e.text)  #adding data to the list\n",
    "experience1=experience_list1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c95d82bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking lenth of each list\n",
    "len(Job_title1), len(company_name1),len(location1), len(experience1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8a995fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver1.close()  # closing the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3ea07eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data analyst/ data analytics / Business analys...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...</td>\n",
       "      <td>Leading US MNC into Analytics</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business analyst + data Analysis</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Anlage Infotech (I) Pvt. Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>upGrad</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Associate Professional Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>DXC Technology</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - Alteryx</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Capco</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Business Analyst - Data Sciences and Ad...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Vmware</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business and Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CAREERDOST ENTERPRISE</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst 2</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                    Data Analyst / Business Analyst   \n",
       "1                    Data Analyst / Business Analyst   \n",
       "2  data analyst/ data analytics / Business analys...   \n",
       "3                   Business analyst + data Analysis   \n",
       "4                                       Data Analyst   \n",
       "5                Associate Professional Data Analyst   \n",
       "6                             Data Analyst - Alteryx   \n",
       "7  Senior Business Analyst - Data Sciences and Ad...   \n",
       "8                          Business and Data Analyst   \n",
       "9                                     Data Analyst 2   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...   \n",
       "3        Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                    company_name experience_required  \n",
       "0             METRO Cash & Carry             3-8 Yrs  \n",
       "1             METRO Cash & Carry             3-8 Yrs  \n",
       "2  Leading US MNC into Analytics             2-7 Yrs  \n",
       "3  Anlage Infotech (I) Pvt. Ltd.            5-10 Yrs  \n",
       "4                         upGrad             1-3 Yrs  \n",
       "5                 DXC Technology             3-6 Yrs  \n",
       "6                          Capco             4-7 Yrs  \n",
       "7                         Vmware             3-7 Yrs  \n",
       "8          CAREERDOST ENTERPRISE             0-5 Yrs  \n",
       "9                         PayPal             1-3 Yrs  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame\n",
    "data1={'Job_title':Job_title1,'Job_location':location1,'company_name':company_name1,'experience_required':experience1}\n",
    "Data_analyst_jobs=pd.DataFrame(data1)\n",
    "\n",
    "# dataframe\n",
    "Data_analyst_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3e196",
   "metadata": {},
   "source": [
    "======================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e078dd2",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6cf76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver2 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5250028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up naukri.com website on automated chrome window\n",
    "driver2.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1189946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for job search bar\n",
    "search_field_designation2=driver2.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_designation2.send_keys('Data scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1316eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location in location bar\n",
    "search_field_loc2=driver2.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "search_field_loc2.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7e995c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search button\n",
    "search_button2=driver2.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div[1]/div[6]\")\n",
    "search_button2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5629f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we will scrape all the tags where we have job titles\n",
    "title_tags2=driver2.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_titles2=[]  # creating empty list\n",
    "for i in title_tags2:   # iterating over each web element of title\n",
    "    job_titles2.append(i.text) #adding values to the list\n",
    "Job_title2=job_titles2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0ba6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job location tags\n",
    "location_tags2=driver2.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]')\n",
    "location_list2=[]  # creating empty  list\n",
    "for l in location_tags2:  # iterating over each web element of location\n",
    "    location_list2.append(l.text)  # adding data to the list\n",
    "location2=location_list2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b78a3625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#firts we will scrape all the tags where we have company names\n",
    "company_tags2=driver2.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "company_names2=[]  # creating empty list\n",
    "for c in company_tags2:   # iterating over each web element of company name\n",
    "    company_names2.append(c.text) #adding data to the list\n",
    "company_name2=company_names2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3d36c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking lenght of each list\n",
    "len(Job_title2), len(location2) ,len(company_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54adbbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver2.close()  # closing the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa9e2992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_name</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Applied Data Scientist / ML Senior Engineer (P...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>SAP India Pvt.Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Analyst - Applied Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Tesco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analyst - Applied Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Tesco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Research Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mavenir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Applied Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Tesco Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist Grade12</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist Grade12</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist / Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_name         Job_location  \\\n",
       "0  Applied Data Scientist / ML Senior Engineer (P...  Bangalore/Bengaluru   \n",
       "1               Sr. Analyst - Applied Data Scientist  Bangalore/Bengaluru   \n",
       "2                 Data Scientist: Advanced Analytics  Bangalore/Bengaluru   \n",
       "3            Data Scientist: Artificial Intelligence  Bangalore/Bengaluru   \n",
       "4                   Analyst - Applied Data Scientist  Bangalore/Bengaluru   \n",
       "5                            Research Data Scientist  Bangalore/Bengaluru   \n",
       "6                        Lead Applied Data Scientist  Bangalore/Bengaluru   \n",
       "7                      Senior Data Scientist Grade12  Bangalore/Bengaluru   \n",
       "8                      Senior Data Scientist Grade12  Bangalore/Bengaluru   \n",
       "9                           Data Scientist / Analyst  Bangalore/Bengaluru   \n",
       "\n",
       "        Company_name  \n",
       "0  SAP India Pvt.Ltd  \n",
       "1              Tesco  \n",
       "2                IBM  \n",
       "3                IBM  \n",
       "4              Tesco  \n",
       "5            Mavenir  \n",
       "6    Tesco Bengaluru  \n",
       "7           Flipkart  \n",
       "8           Flipkart  \n",
       "9      Deutsche Bank  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame\n",
    "data2={'Job_name':Job_title2,'Job_location':location2,'Company_name':company_name2}\n",
    "Data_scientist_jobs=pd.DataFrame(data2)\n",
    "\n",
    "# dataframe\n",
    "Data_scientist_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9217b4",
   "metadata": {},
   "source": [
    "======================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b827a",
   "metadata": {},
   "source": [
    "Q3: write apython program to scrape data from the given link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7e50b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver3 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c98a3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up naukri.com website on automated chrome window\n",
    "driver3.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1bef292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for job search bar\n",
    "search_field_designation3=driver3.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_designation3.send_keys('Data scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "59c3a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search button\n",
    "search_button3=driver3.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div[1]/div[6]\")\n",
    "search_button3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bb85d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location in location bar\n",
    "filter_loc3=driver3.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[3]/label/i\")\n",
    "filter_loc3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0db4ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering salary range\n",
    "filter_salary3=driver3.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[2]/label/i')\n",
    "filter_salary3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aa2bd4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the elements which has title tags\n",
    "title_tags3=driver3.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_title3=[]    # creating empty list to store the titles\n",
    "for i in title_tags3:   # iterating over each web element of title\n",
    "    job_title3.append(i.text)  # adding data to the list\n",
    "job_titles3=job_title3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "67bfe690",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags3=driver3.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]')\n",
    "location_list3=[]\n",
    "for l in location_tags3:   # iterating over each web element of location\n",
    "    location_list3.append(l.text)   # adding data to the list\n",
    "location3=location_list3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1a67b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#firts we will scrape all the tags where we have company names\n",
    "company_tags3=driver3.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "company_names3=[]  # creating empty list\n",
    "for c in company_tags3:   # iterating over each web element of company name\n",
    "    company_names3.append(c.text) #adding data to the list\n",
    "company_name3=company_names3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bdc57957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping experience tags\n",
    "experience_tags3=driver3.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')\n",
    "experience_list3=[]   # creating empty list\n",
    "for e in experience_tags3:   # iterating over each web element of experience\n",
    "    experience_list3.append(e.text)  #adding data to the list\n",
    "experience3=experience_list3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "14b2ef09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking lenth of each list\n",
    "len(job_titles3), len(company_name3),len(location3), len(experience3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c6d4c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver3.close()  # closing the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "587d1d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_name</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Internet Jobs - II</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Jobs Territory</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Scientist - Data Engineering</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AXA Technology Services India Pvt. Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist || Software Company || Immediat...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Skyleaf Consultants</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist (freelance)</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "      <td>2Coms</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist/ Machine Learning, 2022 Passout...</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Delhi /...</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon, Bengaluru</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Analyst and Data Scientist For...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Shadow Placements</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_name  \\\n",
       "0                Data Scientist - Internet Jobs - II   \n",
       "1                                     Data Scientist   \n",
       "2                              Junior Data Scientist   \n",
       "3             Associate Scientist - Data Engineering   \n",
       "4  Data Scientist || Software Company || Immediat...   \n",
       "5                         Data Scientist (freelance)   \n",
       "6  Data Scientist/ Machine Learning, 2022 Passout...   \n",
       "7                                     Data Scientist   \n",
       "8                           Associate Data Scientist   \n",
       "9  Hiring For Data Analyst and Data Scientist For...   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "1                         Noida, Bangalore/Bengaluru   \n",
       "2                                              Noida   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "5                                   New Delhi, Delhi   \n",
       "6  Hyderabad/Secunderabad, Pune, Chennai, Delhi /...   \n",
       "7                                 Gurgaon, Bengaluru   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "\n",
       "                                     Company_name experience_required  \n",
       "0                                  Jobs Territory             3-6 Yrs  \n",
       "1              Ashkom Media India Private Limited             3-6 Yrs  \n",
       "2  EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED             1-2 Yrs  \n",
       "3          AXA Technology Services India Pvt. Ltd             2-5 Yrs  \n",
       "4                             Skyleaf Consultants             3-8 Yrs  \n",
       "5                                           2Coms             2-7 Yrs  \n",
       "6                   Creative Hands HR Consultancy             0-4 Yrs  \n",
       "7                                       BlackBuck             3-7 Yrs  \n",
       "8                                           Optum             1-5 Yrs  \n",
       "9                               Shadow Placements             3-7 Yrs  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame\n",
    "data3={'Job_name':job_titles3,'Job_location':location3,'Company_name':company_name3,'experience_required':experience3}\n",
    "Data_scientist_df=pd.DataFrame(data3)\n",
    "\n",
    "# dataframe\n",
    "Data_scientist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2d71ba",
   "metadata": {},
   "source": [
    "======================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ab2df",
   "metadata": {},
   "source": [
    "Q4:Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "354953e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver4 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a58c84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up flipkart.com website on automated chrome window\n",
    "driver4.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd95e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skippping login\n",
    "skip_login4=driver4.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "skip_login4.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5908e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for sunglasses\n",
    "search_field_product4=driver4.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search_field_product4.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbb16ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking search button\n",
    "search_button4=driver4.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_button4.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b274c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list4=[]   # creating empty list to store brand name\n",
    "product_description4=[]   # creating empty list to store product description\n",
    "price_list4=[]   # creating empty list to store price\n",
    "\n",
    "for i in range(0,3): # running for loop with range to run this loop for 3 times\n",
    "    \n",
    "    #scraping brand name\n",
    "    brand_tags4=driver4.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]') # scraping all the tag names hwere we have brand names\n",
    "    for b in brand_tags4:   # iterating over each web element of brand name\n",
    "        brand_list4.append(b.text)  # adding data to the empty list we created\n",
    "        \n",
    "   #scraping product description     \n",
    "    product_description_tags4=driver4.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    for p in product_description_tags4:   # iterating over each web element of product description\n",
    "        product_description4.append(p.text)  # adding data to the empty list we created\n",
    "        \n",
    "   #scraping price     \n",
    "    price_tags4=driver4.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for pr in price_tags4:   # iterating over each web element of price\n",
    "        price_list4.append(pr.text.replace('‚Çπ',''))  # adding data to the empty list we created\n",
    "        \n",
    "    #locating web element of next button\n",
    "    next_button4=driver4.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button4.click()  # clicking next button \n",
    "    time.sleep(5)\n",
    "    \n",
    "brands4=brand_list4[0:100]\n",
    "description4=product_description4[0:100]\n",
    "price4=price_list4[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6670216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking length of each list\n",
    "len(brands4), len(description4), len(price4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b01bf176",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver4.close()   # closing the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b979c02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price(‚Çπ)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Over-sized Sunglasses (64)</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Others Aviator Sunglasses (63)</td>\n",
       "      <td>5,339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized Retro Square Sunglasses (61)</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (59)</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>United Colors of Benetton</td>\n",
       "      <td>Mirrored, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>1,159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>LOUIS KOUROS</td>\n",
       "      <td>UV Protection Aviator Sunglasses (60)</td>\n",
       "      <td>1,441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Brand  \\\n",
       "0                      PIRASO   \n",
       "1                     Ray-Ban   \n",
       "2                    Fastrack   \n",
       "3                   Elligator   \n",
       "4                    Fastrack   \n",
       "..                        ...   \n",
       "95                  ROYAL SON   \n",
       "96              VINCENT CHASE   \n",
       "97                  ROYAL SON   \n",
       "98  United Colors of Benetton   \n",
       "99               LOUIS KOUROS   \n",
       "\n",
       "                                  Product_description Price(‚Çπ)  \n",
       "0            UV Protection Over-sized Sunglasses (64)      287  \n",
       "1                      Others Aviator Sunglasses (63)    5,339  \n",
       "2       UV Protection Wayfarer Sunglasses (Free Size)      669  \n",
       "3              UV Protection Wayfarer Sunglasses (53)      174  \n",
       "4    UV Protection Rectangular Sunglasses (Free Size)      589  \n",
       "..                                                ...      ...  \n",
       "95             Polarized Retro Square Sunglasses (61)      649  \n",
       "96             UV Protection Wayfarer Sunglasses (59)      749  \n",
       "97  UV Protection Retro Square Sunglasses (Free Size)      449  \n",
       "98      Mirrored, UV Protection Round Sunglasses (50)    1,159  \n",
       "99              UV Protection Aviator Sunglasses (60)    1,441  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making dataframe\n",
    "data4={'Brand':brands4,'Product_description':description4,'Price(‚Çπ)':price4}\n",
    "sunglasses_df=pd.DataFrame(data4)\n",
    "\n",
    "# dataframe\n",
    "sunglasses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87354700",
   "metadata": {},
   "source": [
    "======================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8153e30",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ad74e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver5= webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa19bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up flipkart.com website on automated chrome window\n",
    "driver5.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power- adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "405cfd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on view all reviews\n",
    "view_all5=driver5.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a/div')\n",
    "view_all5.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afb62621",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_list5=[]   # creating empty list to store ratings\n",
    "review_list5=[]   # creating empty list to store review summary\n",
    "full_review_list5=[]   # creating empty list to store full review\n",
    "\n",
    "for i in range(0,11):  # running for loop with range to run this loop for 11 times\n",
    "    \n",
    "    #scraping rating \n",
    "    rating_tags5=driver5.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]') # scraping all the tag names where we have ratings\n",
    "    for r in rating_tags5:\n",
    "        rating_list5.append(r.text)  # adding data to the empty list we created\n",
    "    \n",
    "    #scraping review summary \n",
    "    review_tags5=driver5.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]') # scraping all the tag names where we have review summary\n",
    "    for r in review_tags5:\n",
    "        review_list5.append(r.text)  # adding data to the empty list we created\n",
    "        \n",
    "    #scraping full review\n",
    "    full_review_tags5=driver5.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]') # scraping all the tag names where we have full review\n",
    "    for r in full_review_tags5:\n",
    "        full_review_list5.append(r.text.replace('\\n',' ').strip())  # adding data to the empty list we created\n",
    "    \n",
    "    #locating web element of next button\n",
    "    next_button5=driver5.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "    next_button5.click()  # clicking next button \n",
    "    time.sleep(5)\n",
    "    \n",
    "rating5=rating_list5[0:100]\n",
    "review5=review_list5[0:100]\n",
    "full_review5=full_review_list5[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7245e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking length of each list\n",
    "len(rating5), len(review5), len(full_review5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51a42c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver5.close() # closing the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd612719",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  The iPhone 11 of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Amazing Phone üòçüòçüòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Everything is accept the charging Speed is fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Super ncy I love it‚ù§Ô∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Using my first apple product. ~Camera is good,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Loved it!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5    Terrific purchase   \n",
       "96      5              Awesome   \n",
       "97      5               Super!   \n",
       "98      5               Super!   \n",
       "99      5            Just wow!   \n",
       "\n",
       "                                          Full_review  \n",
       "0   The Best Phone for the Money  The iPhone 11 of...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95                                  Amazing Phone üòçüòçüòç  \n",
       "96  Everything is accept the charging Speed is fan...  \n",
       "97                              Super ncy I love it‚ù§Ô∏è  \n",
       "98  Using my first apple product. ~Camera is good,...  \n",
       "99                                         Loved it!!  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making data frame\n",
    "data5={'Rating':rating5,'Review_summary':review5,'Full_review':full_review5}\n",
    "reviews_df=pd.DataFrame(data5)\n",
    "\n",
    "#dataframe\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e623c",
   "metadata": {},
   "source": [
    "======================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006dc3af",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8fa17cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver6 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a0aa97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up flipkart.com website on automated chrome window\n",
    "driver6.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "799f4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skippping login\n",
    "skip_login6=driver6.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "skip_login6.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3840f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for sneakers\n",
    "search_field_product6=driver6.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search_field_product6.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74c0dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking search button\n",
    "search_button6=driver6.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_button6.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5788cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list6=[]   # creating empty list to store brand name\n",
    "product_description6=[]   # creating empty list to store product description\n",
    "price_list6=[]   # creating empty list to store price\n",
    "\n",
    "for i in range(0,4):  # running for loop with range to run this loop for 4 times\n",
    "    \n",
    "    #scraping brand name\n",
    "    brand_tags6=driver6.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]') # scraping all the tag names hwere we have brand names\n",
    "    for b in brand_tags6:\n",
    "        brand_list6.append(b.text)  # adding data to the empty list we created\n",
    "        \n",
    "    #scraping product description   \n",
    "    product_description_tags6=driver6.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    for p in product_description_tags6:\n",
    "        product_description6.append(p.text)  # adding data to the empty list we created\n",
    "        \n",
    "    #scraping price  \n",
    "    price_tags6=driver6.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for pr in price_tags6:\n",
    "        price_list6.append(pr.text.replace('‚Çπ',''))  # adding data to the empty list we created\n",
    "        \n",
    "    #locating web element of next button\n",
    "    next_button6=driver6.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button6.click()  # clicking next button \n",
    "    time.sleep(5)\n",
    "    \n",
    "brands6=brand_list6[0:100]\n",
    "description6=product_description6[0:100]\n",
    "price6=price_list6[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a0f422f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brands6),len(description6),len(price6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf6f9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver6.close() # closing the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "76c130ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price(‚Çπ)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bacan</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>STYLISH MENS BLACK AND WHITE SNEAKER Sneakers ...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Stylish Comfortable Lightweight, Breathable Wa...</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corsac</td>\n",
       "      <td>Sneaker Sneakers For Men</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>MOZAFIA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Rebound Future Cage Sneakers For Men</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NIKE</td>\n",
       "      <td>Fashion and Stylish Soft Ultralight Lace Up Sn...</td>\n",
       "      <td>2,997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>1,569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FAUSTO</td>\n",
       "      <td>SPORT COURT 92 Sneakers For Men</td>\n",
       "      <td>1,119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                Product_description Price(‚Çπ)\n",
       "0      Bacan                                   Sneakers For Men      449\n",
       "1   RapidBox      Modern Trendy Sneakers Shoes Sneakers For Men      630\n",
       "2   URBANBOX  STYLISH MENS BLACK AND WHITE SNEAKER Sneakers ...      148\n",
       "3     BRUTON  Stylish Comfortable Lightweight, Breathable Wa...      245\n",
       "4     corsac                           Sneaker Sneakers For Men      449\n",
       "..       ...                                                ...      ...\n",
       "95   MOZAFIA                                   Sneakers For Men      849\n",
       "96    Labbin               Rebound Future Cage Sneakers For Men      369\n",
       "97      NIKE  Fashion and Stylish Soft Ultralight Lace Up Sn...    2,997\n",
       "98    DUCATI                                   Sneakers For Men    1,569\n",
       "99    FAUSTO                    SPORT COURT 92 Sneakers For Men    1,119\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making data frame\n",
    "data6={'Brand':brands6,'Product_description':description6,'Price(‚Çπ)':price6}\n",
    "sneakers_df=pd.DataFrame(data6)\n",
    "\n",
    "#dataframe\n",
    "sneakers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1dc798",
   "metadata": {},
   "source": [
    "======================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cebcc1",
   "metadata": {},
   "source": [
    "Q7: write a python program to scrape data from the given link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f6f429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver7 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5dd3f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up myntra.com website on automated chrome window\n",
    "driver7.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d638175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering price\n",
    "filter_price7=driver7.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label')\n",
    "filter_price7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16329c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering black colour\n",
    "filter_colour7=driver7.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label')\n",
    "filter_colour7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "81d277d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering price\n",
    "filter_price7=driver7.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label')\n",
    "filter_price7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea3f7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list7=[]   # creating empty list to store brand name\n",
    "product_description7=[]   # creating empty list to store product description\n",
    "price_list7=[]   # creating empty list to store price\n",
    "\n",
    "for i in range(0,2): # running for loop with range to run this loop 2 times \n",
    "    \n",
    "    #scraping brand name\n",
    "    brand_tags7=driver7.find_elements_by_xpath('//h3[@class=\"product-brand\"]') # scraping all the tag names where we have brand names\n",
    "    for b in brand_tags7:   # iterating over each web element of brand name\n",
    "        brand_list7.append(b.text)  # adding data to the empty list we created\n",
    "        \n",
    "    #scraping product description   \n",
    "    product_description_tags7=driver7.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "    for p in product_description_tags7:   # iterating over each web element of descriotion\n",
    "        product_description7.append(p.text)  # adding data to the empty list we created\n",
    "        \n",
    "    #scraping price    \n",
    "    price_tags7=driver7.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "    for pr in price_tags7: # iterating over each web element of price\n",
    "        price_list7.append(pr.text.replace('Rs.',''))  # adding data to the empty list we created\n",
    "        \n",
    "    #locating web element of next button   \n",
    "    next_button7=driver7.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]')\n",
    "    next_button7.click()  # clicking next button \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aff33dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the length of each list\n",
    "len(brand_list7),len(product_description7),len(price_list7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42e757b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver7.close() # closing the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2dcab7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short_shoe_description</th>\n",
       "      <th>Price(Rs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>7199 8999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Miler2 Running Shoes</td>\n",
       "      <td>11495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women React MR 3 Running Shoes</td>\n",
       "      <td>8920 10495(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR MAX EXCEE Sneakers</td>\n",
       "      <td>7995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Men Textured Formal Leather Loafers</td>\n",
       "      <td>8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Formal Leather Derby</td>\n",
       "      <td>7990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Block Pumps with Bows</td>\n",
       "      <td>8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Leather Loafers</td>\n",
       "      <td>11899 16999(30% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand               Short_shoe_description  \\\n",
       "0               Skechers           Men Max Cushioning Running   \n",
       "1                   Nike       Men React Miler2 Running Shoes   \n",
       "2                   ALDO                         Men Sneakers   \n",
       "3                   Nike       Women React MR 3 Running Shoes   \n",
       "4                   Nike           Men AIR MAX EXCEE Sneakers   \n",
       "..                   ...                                  ...   \n",
       "95              DAVINCHI  Men Textured Formal Leather Loafers   \n",
       "96  Heel & Buckle London             Men Formal Leather Derby   \n",
       "97             J.FONTINI           Men Leather Formal Loafers   \n",
       "98                  ALDO                Block Pumps with Bows   \n",
       "99             Cole Haan                Women Leather Loafers   \n",
       "\n",
       "                Price(Rs)  \n",
       "0      7199 8999(20% OFF)  \n",
       "1                   11495  \n",
       "2                    9999  \n",
       "3     8920 10495(15% OFF)  \n",
       "4                    7995  \n",
       "..                    ...  \n",
       "95                   8990  \n",
       "96                   7990  \n",
       "97                   7490  \n",
       "98                   8999  \n",
       "99   11899 16999(30% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making data frame\n",
    "data7={'Brand':brand_list7,'Short_shoe_description':product_description7,'Price(Rs)':price_list7}\n",
    "shoe_df=pd.DataFrame(data7)\n",
    "\n",
    "#dataframe\n",
    "shoe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5db1950",
   "metadata": {},
   "source": [
    "========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8752d",
   "metadata": {},
   "source": [
    "Q8:scrape the data from given link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "64cbb384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver8 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3f99c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up amazon.com website on automated chrome window\n",
    "driver8.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0ae7248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering laptops in search box\n",
    "field_search8=driver8.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "field_search8.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4d0528dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search button\n",
    "search_button8=driver8.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search_button8.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6b17b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying cpu type filter\n",
    "filter_cpu_type8=driver8.find_element_by_xpath('//li[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span[1]')\n",
    "filter_cpu_type8.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c9f616e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping title,ratings and price of laptops\n",
    "\n",
    "laptop_title8=[]   # creating empty list to store title\n",
    "title_tags8=driver8.find_elements_by_xpath('//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "for i in title_tags8:  # iterating over each web element of title\n",
    "    laptop_title8.append(i.text.strip())\n",
    "laptop_name8=laptop_title8[0:10]\n",
    "\n",
    "product_ratings=[]\n",
    "# find ratings box\n",
    "ratings_box = driver8.find_elements_by_xpath('//div[@class=\"a-section a-spacing-none a-spacing-top-micro\"]/div/span')\n",
    "# find ratings\n",
    "for i in ratings_box:\n",
    "    ratings = ratings_box[0].get_attribute('aria-label')\n",
    "    product_ratings.append(ratings)\n",
    "ratings8=product_ratings[0:10]\n",
    "\n",
    "price8=[] # creating the empty list to store priice\n",
    "price_tags8=driver8.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "for p in price_tags8:   # iterating over each web element of price\n",
    "    price8.append(p.text.replace('‚Çπ','').strip())\n",
    "laptop_price8=price8[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d3f09563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the length of each list\n",
    "len(laptop_name8), len(ratings8), len(laptop_price8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "668f5abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver8.close() # closing the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c47e13ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price(‚Çπ)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Predator Helios 300 11th Gen Intel Core i...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>1,69,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>58,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Ultra 3.2K Resolution Display Inte...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>77,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>86,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>57,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>85,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LG Gram 14 Intel Evo 11th Gen Core i7 14 inche...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>85,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  Acer Predator Helios 300 11th Gen Intel Core i...  5.0 out of 5 stars   \n",
       "1  Mi Notebook Horizon Edition 14 Intel Core i7-1...  5.0 out of 5 stars   \n",
       "2  Mi Notebook Ultra 3.2K Resolution Display Inte...  5.0 out of 5 stars   \n",
       "3  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  5.0 out of 5 stars   \n",
       "4  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...  5.0 out of 5 stars   \n",
       "5  HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...  5.0 out of 5 stars   \n",
       "6  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  5.0 out of 5 stars   \n",
       "7  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...  5.0 out of 5 stars   \n",
       "8  HP Pavilion x360 11th Gen Intel Core i7 14 inc...  5.0 out of 5 stars   \n",
       "9  LG Gram 14 Intel Evo 11th Gen Core i7 14 inche...  5.0 out of 5 stars   \n",
       "\n",
       "   Price(‚Çπ)  \n",
       "0  1,69,990  \n",
       "1    58,999  \n",
       "2    77,999  \n",
       "3    86,900  \n",
       "4    57,490  \n",
       "5    86,990  \n",
       "6    79,990  \n",
       "7    89,990  \n",
       "8    85,890  \n",
       "9    85,999  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame\n",
    "data8={'Title':laptop_name8,'Ratings':ratings8,'Price(‚Çπ)':laptop_price8}\n",
    "laptops_df=pd.DataFrame(data8)\n",
    "\n",
    "# dataframe\n",
    "laptops_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daff2ee",
   "metadata": {},
   "source": [
    "========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac126dc",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location from https://www.ambitionbox.com/. \n",
    "        You have to scrape company name, \n",
    "        No. of days ago when job was posted, \n",
    "        Rating of the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "888b7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver9 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95942280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up ambitionbox.com website on automated chrome window\n",
    "driver9.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "12c23b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on jobs\n",
    "click_jobs9=driver9.find_element_by_xpath('/html/body/div[1]/nav/nav/a[6]')\n",
    "click_jobs9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "02eeb55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for job search\n",
    "search_designation9=driver9.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "search_designation9.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "12512326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search button\n",
    "click_search_button9=driver9.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button')\n",
    "click_search_button9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5ae0f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on location button\n",
    "click_location_button9=driver9.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/p')\n",
    "click_location_button9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e98c26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search location\n",
    "search_location9=driver9.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "search_location9.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "354d9a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select location Noida\n",
    "select_noida9=driver9.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/input')\n",
    "select_noida9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4d5f8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping company name\n",
    "company_name9=[]  # creating empty list to store company name\n",
    "#scraping all the tags where we have company name\n",
    "company_name_tags9=driver9.find_elements_by_xpath('//p[@class=\"company body-medium\"]')\n",
    "for i in company_name_tags9:  # iterating over each web element of company name\n",
    "    company_name9.append(i.text)  # adding data to the empty list\n",
    "\n",
    "#scraping no. of days job was posted\n",
    "days_ago9=[]  # creating empty list to store data\n",
    "# scraping all the tags where we have tags of job posted days ago\n",
    "days_ago_tags9=driver9.find_elements_by_xpath('//span[@class=\"body-small-l\"]')\n",
    "for i in days_ago_tags9:   # iterating over each web element of job posted days ago\n",
    "    days_ago9.append(i.text)\n",
    "days9=days_ago9[0::2]\n",
    "\n",
    "#scraping ratings of the company\n",
    "ratings9=[]  # creating empty list to store ratings of the company\n",
    "# scraping all the tags where we have ratings\n",
    "ratings_tags9=driver9.find_elements_by_xpath('//span[@class=\"body-small\"]')\n",
    "for i in ratings_tags9:   # iterating over each web element of ratings\n",
    "    ratings9.append(i.text) # adding values top the empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "80d3b572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the length of each list\n",
    "len(company_name9), len(days9), len(ratings9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3a2a930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver9.close() # closing the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0bc1efe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Days_ago_job_posted</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>18hr ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>23d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TECHNIP GLOBAL BUSINESS SERVICES PRIVATE LIMITED</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bristlecone India Limited</td>\n",
       "      <td>18d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zyoin</td>\n",
       "      <td>22d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Newgen Software Technologies Ltd.</td>\n",
       "      <td>24d ago</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pitney Bowes India Pvt Ltd</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Company_name Days_ago_job_posted  \\\n",
       "0          Ericsson India Global Services Pvt. Ltd.            18hr ago   \n",
       "1                  EXL Services.com ( I ) Pvt. Ltd.             11d ago   \n",
       "2                     GENPACT India Private Limited             23d ago   \n",
       "3  TECHNIP GLOBAL BUSINESS SERVICES PRIVATE LIMITED              9d ago   \n",
       "4                     GENPACT India Private Limited            1mon ago   \n",
       "5                         Bristlecone India Limited             18d ago   \n",
       "6                                             Zyoin             22d ago   \n",
       "7                Ashkom Media India Private Limited              9d ago   \n",
       "8                 Newgen Software Technologies Ltd.             24d ago   \n",
       "9                        Pitney Bowes India Pvt Ltd            1mon ago   \n",
       "\n",
       "  Ratings  \n",
       "0     4.3  \n",
       "1     3.9  \n",
       "2     4.0  \n",
       "3     3.9  \n",
       "4     4.0  \n",
       "5     3.8  \n",
       "6     4.1  \n",
       "7     3.7  \n",
       "8     3.6  \n",
       "9     4.2  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making dataframe\n",
    "data9={'Company_name':company_name9,'Days_ago_job_posted':days9,'Ratings':ratings9}\n",
    "\n",
    "Datascientist_jobs_df=pd.DataFrame(data9)\n",
    "\n",
    "#dataframe\n",
    "Datascientist_jobs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9225e28c",
   "metadata": {},
   "source": [
    "========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2dcbbe",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3852cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver10 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d5545f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up ambitionbox.com website on automated chrome window\n",
    "driver10.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2b1f5b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on salaries\n",
    "click_salaries10=driver10.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "click_salaries10.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "57dabd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for salaries search\n",
    "search_job_profile10=driver10.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "search_job_profile10.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7cfbb5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping company name\n",
    "company_name10=[]  # creating empty list to store company name\n",
    "#scraping all the tags where we have company name\n",
    "company_name_tags10=driver10.find_elements_by_xpath('//div[@class=\"company-info\"]/div/a')\n",
    "for i in company_name_tags10:   # iterating over each web element of company name\n",
    "    company_name10.append(i.text)  # adding data to the empty list\n",
    "    \n",
    "#scraping total salay record\n",
    "number_of_salaries10=[]\n",
    "#lets scrape all the tags where we have salaries tags\n",
    "salaries_tags10=driver10.find_elements_by_xpath('//div[@class=\"company-info\"]/div/span')\n",
    "for i in salaries_tags10:    # iterating over each web element of number of salaries\n",
    "    number_of_salaries10.append(i.text)\n",
    "salaries10=number_of_salaries10[0::2]\n",
    "\n",
    "#scraping average salary\n",
    "average_salary10=[]\n",
    "#lets scrape all the tags where we have average salary\n",
    "average_salary_tags10=driver10.find_elements_by_xpath('//p[@class=\"averageCtc\"]')\n",
    "for i in average_salary_tags10:   # iterating over each web element of average salary\n",
    "    average_salary10.append(i.text.replace('‚Çπ',''))\n",
    "\n",
    "#scraping minimum salary\n",
    "min_salary10=[]\n",
    "#lets scarpe all the tags where we have minimum salary\n",
    "min_salary_tags10=driver10.find_elements_by_xpath('//div[@class=\"value body-medium\"]')\n",
    "for i in min_salary_tags10:    # iterating over each web element of minimum salary\n",
    "    min_salary10.append(i.text.replace('‚Çπ',''))\n",
    "minimum_salary10=min_salary10[0::2]\n",
    "\n",
    "#scraping maximum salary\n",
    "max_salary10=[]\n",
    "#lets scarpe all the tags where we have maximum salary\n",
    "max_salary_tags10=driver10.find_elements_by_xpath('//div[@class=\"value body-medium\"]')\n",
    "for i in max_salary_tags10:    # iterating over each web element of maximum salary\n",
    "    max_salary10.append(i.text.replace('‚Çπ',''))\n",
    "maximum_salary10=max_salary10[1::2]\n",
    "\n",
    "#scraping experience required\n",
    "exp_required10=[]\n",
    "#lets scrape all the tags where we have experience required\n",
    "exp_required_tags10=driver10.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]')\n",
    "for i in exp_required_tags10:   # iterating over each web element of experience required\n",
    "    exp_required10.append(i.text.replace('Data Scientist\\n . \\n','').replace('exp',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3f278df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10, 10, 10)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking length of each list\n",
    "len(company_name10), len(salaries10), len(average_salary10), len(minimum_salary10), len(maximum_salary10), len(exp_required10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "275f0c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver10.close() # closing the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b15ce0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Number_of_salaries</th>\n",
       "      <th>Average_salary(‚Çπ)</th>\n",
       "      <th>Minimum_salary(‚Çπ)</th>\n",
       "      <th>Maximum_salary(‚Çπ)</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>29.7L</td>\n",
       "      <td>25.0L</td>\n",
       "      <td>35.0L</td>\n",
       "      <td>3 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 32 salaries</td>\n",
       "      <td>20.5L</td>\n",
       "      <td>15.0L</td>\n",
       "      <td>25.5L</td>\n",
       "      <td>3-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>18.9L</td>\n",
       "      <td>5.6L</td>\n",
       "      <td>26.2L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "      <td>16.7L</td>\n",
       "      <td>11.0L</td>\n",
       "      <td>22.0L</td>\n",
       "      <td>2 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 30 salaries</td>\n",
       "      <td>15.9L</td>\n",
       "      <td>11.0L</td>\n",
       "      <td>22.6L</td>\n",
       "      <td>3-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 82 salaries</td>\n",
       "      <td>15.4L</td>\n",
       "      <td>9.7L</td>\n",
       "      <td>23.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 47 salaries</td>\n",
       "      <td>14.8L</td>\n",
       "      <td>9.0L</td>\n",
       "      <td>20.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 55 salaries</td>\n",
       "      <td>13.9L</td>\n",
       "      <td>8.3L</td>\n",
       "      <td>20.5L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>12.7L</td>\n",
       "      <td>10.0L</td>\n",
       "      <td>21.0L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>12.4L</td>\n",
       "      <td>8.5L</td>\n",
       "      <td>15.0L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company_name    Number_of_salaries Average_salary(‚Çπ)  \\\n",
       "0                   Walmart  based on 11 salaries             29.7L   \n",
       "1                  Ab Inbev  based on 32 salaries             20.5L   \n",
       "2              Reliance Jio  based on 10 salaries             18.9L   \n",
       "3                        ZS  based on 15 salaries             16.7L   \n",
       "4                     Optum  based on 30 salaries             15.9L   \n",
       "5         Fractal Analytics  based on 82 salaries             15.4L   \n",
       "6           Tiger Analytics  based on 47 salaries             14.8L   \n",
       "7              UnitedHealth  based on 55 salaries             13.9L   \n",
       "8                   Verizon  based on 14 salaries             12.7L   \n",
       "9  Ganit Business Solutions  based on 13 salaries             12.4L   \n",
       "\n",
       "  Minimum_salary(‚Çπ) Maximum_salary(‚Çπ) Experience_required  \n",
       "0             25.0L             35.0L              3 yrs   \n",
       "1             15.0L             25.5L            3-4 yrs   \n",
       "2              5.6L             26.2L              4 yrs   \n",
       "3             11.0L             22.0L              2 yrs   \n",
       "4             11.0L             22.6L            3-4 yrs   \n",
       "5              9.7L             23.0L            2-4 yrs   \n",
       "6              9.0L             20.0L            2-4 yrs   \n",
       "7              8.3L             20.5L            2-4 yrs   \n",
       "8             10.0L             21.0L              4 yrs   \n",
       "9              8.5L             15.0L              4 yrs   "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making dataframe\n",
    "data10={'Company_name':company_name10,'Number_of_salaries':salaries10,'Average_salary(‚Çπ)':average_salary10,'Minimum_salary(‚Çπ)':minimum_salary10,'Maximum_salary(‚Çπ)':maximum_salary10,'Experience_required':exp_required10}\n",
    "Salaries_df = pd.DataFrame(data10)\n",
    "\n",
    "#dataframe\n",
    "Salaries_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
