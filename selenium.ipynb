{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "6f5338ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import alll reqired libraries\n",
    "import selenium                  #library to work with selenium\n",
    "import pandas as pd              # library to make dataframe\n",
    "from selenium import webdriver   # import webdriver module fromv selelnium to open up automated chrome window\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore any sort of warnings\n",
    "import time                      # to stop search engine for few seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b6fb3",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10a64e",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for ‚ÄúData Analyst‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ed216f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver1 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "b4581371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up naukri.com website on automated chrome window\n",
    "driver1.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "6202fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for job search bar\n",
    "search_field_designation1=driver1.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_designation1.send_keys('Data analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "b24bc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location in location bar\n",
    "search_field_loc1=driver1.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "search_field_loc1.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "a7a586ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search button\n",
    "search_button1=driver1.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div[1]/div[6]\")\n",
    "search_button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "7ded71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we will scrape all the tags where we have job titles\n",
    "title_tags1=driver1.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_titles1=[]  # creating empty list\n",
    "for i in title_tags1: \n",
    "    job_titles1.append(i.text) #adding values to the list\n",
    "Job_title1=job_titles1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "5b6f1de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#firts we will scrape all the tags where we have company names\n",
    "company_tags1=driver1.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "company_names1=[]  # creating empty list\n",
    "for c in company_tags1:\n",
    "    company_names1.append(c.text) #adding data to the list\n",
    "company_name1=company_names1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "df2f57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job location tags\n",
    "location_tags1=driver1.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]')\n",
    "location_list1=[]  # creating empty  list\n",
    "for l in location_tags1:\n",
    "    location_list1.append(l.text)  # adding data to the list\n",
    "location1=location_list1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "99ab521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags1=driver1.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')\n",
    "experience_list1=[]   # creating empty list\n",
    "for e in experience_tags1:\n",
    "    experience_list1.append(e.text)  #adding data to the list\n",
    "experience1=experience_list1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "4dcc7d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver1.close()  # closing the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "c95d82bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking lenth of each list\n",
    "len(Job_title1), len(company_name1),len(location1), len(experience1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "c3ea07eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr Data Analyst II</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business analyst + data Analysis</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Anlage Infotech (I) Pvt. Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consultant - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For Data Analyst with SAP ABAP &amp; BW - C...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>MILLION MINDS INFOTECH PRIVATE LIMITED</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Business Analyst - Data Sciences and Ad...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Vmware</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business and Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CAREERDOST ENTERPRISE</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst | Lululemon</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TALENT500 TECH (INDIA) PRIVATE LIMITED</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Urgent hiring For Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>upGrad</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                 Sr Data Analyst II   \n",
       "2                   Business analyst + data Analysis   \n",
       "3                          Consultant - Data Analyst   \n",
       "4  Hiring For Data Analyst with SAP ABAP & BW - C...   \n",
       "5  Senior Business Analyst - Data Sciences and Ad...   \n",
       "6                          Business and Data Analyst   \n",
       "7                    Senior Data Analyst | Lululemon   \n",
       "8              Urgent hiring For Senior Data Analyst   \n",
       "9                                Senior Data Analyst   \n",
       "\n",
       "                                  Job_location  \\\n",
       "0                          Bangalore/Bengaluru   \n",
       "1        Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "2  Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "3                          Bangalore/Bengaluru   \n",
       "4                          Bangalore/Bengaluru   \n",
       "5                          Bangalore/Bengaluru   \n",
       "6                          Bangalore/Bengaluru   \n",
       "7                          Bangalore/Bengaluru   \n",
       "8                          Bangalore/Bengaluru   \n",
       "9                          Bangalore/Bengaluru   \n",
       "\n",
       "                             company_name experience_required  \n",
       "0                                Flipkart             3-7 Yrs  \n",
       "1                              IHS Markit             3-6 Yrs  \n",
       "2           Anlage Infotech (I) Pvt. Ltd.            5-10 Yrs  \n",
       "3                                Flipkart             1-3 Yrs  \n",
       "4  MILLION MINDS INFOTECH PRIVATE LIMITED            7-10 Yrs  \n",
       "5                                  Vmware             3-7 Yrs  \n",
       "6                   CAREERDOST ENTERPRISE             0-5 Yrs  \n",
       "7  TALENT500 TECH (INDIA) PRIVATE LIMITED             5-8 Yrs  \n",
       "8                                  upGrad             2-7 Yrs  \n",
       "9                         Thomson Reuters             2-4 Yrs  "
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame\n",
    "data1={'Job_title':Job_title1,'Job_location':location1,'company_name':company_name1,'experience_required':experience1}\n",
    "Data_analyst_jobs=pd.DataFrame(data1)\n",
    "\n",
    "# dataframe\n",
    "Data_analyst_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3e196",
   "metadata": {},
   "source": [
    "========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e078dd2",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "d6cf76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver2 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "5250028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up naukri.com website on automated chrome window\n",
    "driver2.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "c1189946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for job search bar\n",
    "search_field_designation2=driver2.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_designation2.send_keys('Data scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b1316eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location in location bar\n",
    "search_field_loc2=driver2.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "search_field_loc2.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "b7e995c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search button\n",
    "search_button2=driver2.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div[1]/div[6]\")\n",
    "search_button2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "c5629f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we will scrape all the tags where we have job titles\n",
    "title_tags2=driver2.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_titles2=[]  # creating empty list\n",
    "for i in title_tags2: \n",
    "    job_titles2.append(i.text) #adding values to the list\n",
    "Job_title2=job_titles2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b0ba6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job location tags\n",
    "location_tags2=driver2.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]')\n",
    "location_list2=[]  # creating empty  list\n",
    "for l in location_tags2:\n",
    "    location_list2.append(l.text)  # adding data to the list\n",
    "location2=location_list2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "b78a3625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#firts we will scrape all the tags where we have company names\n",
    "company_tags2=driver2.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "company_names2=[]  # creating empty list\n",
    "for c in company_tags2:\n",
    "    company_names2.append(c.text) #adding data to the list\n",
    "company_name2=company_names2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "e4bf1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver2.close()  # closing the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "f3d36c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking lenght of each list\n",
    "len(Job_title2), len(location2) ,len(company_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "fa9e2992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_name</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Applied Data Scientist / ML Senior Engineer (P...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>SAP India Pvt.Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist Grade12</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist Grade12</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>Genpact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>VISA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist, Machine Learning (AIML)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist / Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_name  \\\n",
       "0  Applied Data Scientist / ML Senior Engineer (P...   \n",
       "1                      Senior Data Scientist Grade12   \n",
       "2                      Senior Data Scientist Grade12   \n",
       "3                              Senior Data Scientist   \n",
       "4                 Data Scientist: Advanced Analytics   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7            Data Scientist: Artificial Intelligence   \n",
       "8            Data Scientist, Machine Learning (AIML)   \n",
       "9                           Data Scientist / Analyst   \n",
       "\n",
       "                                        Job_location       Company_name  \n",
       "0                                Bangalore/Bengaluru  SAP India Pvt.Ltd  \n",
       "1                                Bangalore/Bengaluru           Flipkart  \n",
       "2                                Bangalore/Bengaluru           Flipkart  \n",
       "3                                Bangalore/Bengaluru  Fractal Analytics  \n",
       "4                                Bangalore/Bengaluru                IBM  \n",
       "5  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...            Genpact  \n",
       "6                                Bangalore/Bengaluru               VISA  \n",
       "7                                Bangalore/Bengaluru                IBM  \n",
       "8                                Bangalore/Bengaluru  Fractal Analytics  \n",
       "9                                Bangalore/Bengaluru      Deutsche Bank  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame\n",
    "data2={'Job_name':Job_title2,'Job_location':location2,'Company_name':company_name2}\n",
    "Data_scientist_jobs=pd.DataFrame(data2)\n",
    "\n",
    "# dataframe\n",
    "Data_scientist_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9217b4",
   "metadata": {},
   "source": [
    "========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b827a",
   "metadata": {},
   "source": [
    "Q3: write apython program to scrape data from the given link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "7e50b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver3 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "c98a3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up naukri.com website on automated chrome window\n",
    "driver3.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "1bef292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for job search bar\n",
    "search_field_designation3=driver3.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_designation3.send_keys('Data scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "59c3a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search button\n",
    "search_button3=driver3.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div[1]/div[6]\")\n",
    "search_button3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "bb85d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location in location bar\n",
    "filter_loc3=driver3.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[3]/label/i\")\n",
    "filter_loc3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0db4ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering salary range\n",
    "filter_salary3=driver3.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[2]/label/i')\n",
    "filter_salary3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "aa2bd4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the elements which has title tags\n",
    "title_tags3=driver3.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_title3=[]    # creating empty list to store the titles\n",
    "for i in title_tags3:\n",
    "    job_title3.append(i.text)  # adding data to the list\n",
    "job_titles3=job_title3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "67bfe690",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags3=driver3.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]')\n",
    "location_list3=[]\n",
    "for l in location_tags3:\n",
    "    location_list3.append(l.text)   # adding data to the list\n",
    "location3=location_list3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "1a67b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#firts we will scrape all the tags where we have company names\n",
    "company_tags3=driver3.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "company_names3=[]  # creating empty list\n",
    "for c in company_tags3:\n",
    "    company_names3.append(c.text) #adding data to the list\n",
    "company_name3=company_names3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "bdc57957",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags3=driver3.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')\n",
    "experience_list3=[]   # creating empty list\n",
    "for e in experience_tags3:\n",
    "    experience_list3.append(e.text)  #adding data to the list\n",
    "experience3=experience_list3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "7be84140",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver3.close()  # closing the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "14b2ef09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking lenth of each list\n",
    "len(job_titles3), len(company_name3),len(location3), len(experience3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "587d1d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_name</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Scientist - Data Engineering</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AXA Technology Services India Pvt. Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For Data Analyst and Data Scientist For...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Shadow Placements</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist || Software Company || Immediat...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Skyleaf Consultants</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist (freelance)</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "      <td>2Coms</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist/ Machine Learning, 2022 Passout...</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Delhi /...</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Nibha Infotech Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon, Bengaluru</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_name  \\\n",
       "0                                     Data Scientist   \n",
       "1                              Junior Data Scientist   \n",
       "2                           Associate Data Scientist   \n",
       "3             Associate Scientist - Data Engineering   \n",
       "4  Hiring For Data Analyst and Data Scientist For...   \n",
       "5  Data Scientist || Software Company || Immediat...   \n",
       "6                         Data Scientist (freelance)   \n",
       "7  Data Scientist/ Machine Learning, 2022 Passout...   \n",
       "8                                    Data Scientists   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                         Noida, Bangalore/Bengaluru   \n",
       "1                                              Noida   \n",
       "2                                   Gurgaon/Gurugram   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "5              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "6                                   New Delhi, Delhi   \n",
       "7  Hyderabad/Secunderabad, Pune, Chennai, Delhi /...   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9                                 Gurgaon, Bengaluru   \n",
       "\n",
       "                                     Company_name experience_required  \n",
       "0              Ashkom Media India Private Limited             3-6 Yrs  \n",
       "1  EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED             1-2 Yrs  \n",
       "2                                           Optum             1-5 Yrs  \n",
       "3          AXA Technology Services India Pvt. Ltd             2-5 Yrs  \n",
       "4                               Shadow Placements             3-7 Yrs  \n",
       "5                             Skyleaf Consultants             3-8 Yrs  \n",
       "6                                           2Coms             2-7 Yrs  \n",
       "7                   Creative Hands HR Consultancy             0-4 Yrs  \n",
       "8                  Nibha Infotech Private Limited             5-8 Yrs  \n",
       "9                                       BlackBuck             3-7 Yrs  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# creating data frame\n",
    "data3={'Job_name':job_titles3,'Job_location':location3,'Company_name':company_name3,'experience_required':experience3}\n",
    "Data_scientist_df=pd.DataFrame(data3)\n",
    "\n",
    "# dataframe\n",
    "Data_scientist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2d71ba",
   "metadata": {},
   "source": [
    "========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ab2df",
   "metadata": {},
   "source": [
    "Q4:Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "354953e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver4 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "a58c84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up flipkart.com website on automated chrome window\n",
    "driver4.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "4bcb7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skippping login\n",
    "skip_login4=driver4.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "skip_login4.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "5908e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for sunglasses\n",
    "search_field_product4=driver4.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search_field_product4.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "dbb16ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking search button\n",
    "search_button4=driver4.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_button4.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "b274c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list4=[]   # creating empty list to store brand name\n",
    "product_description4=[]   # creating empty list to store product description\n",
    "price_list4=[]   # creating empty list to store price\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    #scraping brand name\n",
    "    brand_tags4=driver4.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]') # scraping all the tag names hwere we have brand names\n",
    "    for b in brand_tags4:\n",
    "        brand_list4.append(b.text)  # adding data to the empty list we created\n",
    "        \n",
    "   #scraping product description     \n",
    "    product_description_tags4=driver4.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    for p in product_description_tags4:\n",
    "        product_description4.append(p.text)  # adding data to the empty list we created\n",
    "        \n",
    "   #scraping price     \n",
    "    price_tags4=driver4.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for pr in price_tags4:\n",
    "        price_list4.append(pr.text.replace('‚Çπ',''))  # adding data to the empty list we created\n",
    "        \n",
    "    #clicking next button\n",
    "    next_button4=driver4.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button4.click()  # clicking next button \n",
    "    time.sleep(5)\n",
    "    \n",
    "brands4=brand_list4[0:100]\n",
    "description4=product_description4[0:100]\n",
    "price4=price_list4[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "5c3175e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brands4), len(description4), len(price4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "b01bf176",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver4.close()   # closing the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "b979c02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price(‚Çπ)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Over-sized Sunglasses (64)</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (50)</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Butterfly Sunglasses (60)</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>UV Protection Round Sunglasses (50)</td>\n",
       "      <td>5,984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Retro Squar...</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Over-sized ...</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product_description Price(‚Çπ)\n",
       "0           PIRASO           UV Protection Over-sized Sunglasses (64)      399\n",
       "1    VINCENT CHASE          UV Protection Rectangular Sunglasses (50)      649\n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)      647\n",
       "3           SUNBEE  UV Protection, Polarized Wayfarer Sunglasses (...      283\n",
       "4         Fastrack   UV Protection Rectangular Sunglasses (Free Size)      639\n",
       "..             ...                                                ...      ...\n",
       "95          PIRASO            UV Protection Butterfly Sunglasses (60)      410\n",
       "96         Ray-Ban                UV Protection Round Sunglasses (50)    5,984\n",
       "97  kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...      269\n",
       "98          AISLIN  UV Protection, Gradient Butterfly, Retro Squar...      498\n",
       "99          AISLIN  UV Protection, Gradient Butterfly, Over-sized ...      498\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making dataframe\n",
    "data4={'Brand':brands4,'Product_description':description4,'Price(‚Çπ)':price4}\n",
    "sunglasses_df=pd.DataFrame(data4)\n",
    "\n",
    "# dataframe\n",
    "sunglasses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87354700",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8153e30",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "8ad74e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver5= webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "aa19bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up flipkart.com website on automated chrome window\n",
    "driver5.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power- adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "405cfd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on view all reviews\n",
    "view_all5=driver5.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a/div')\n",
    "view_all5.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "afb62621",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_list5=[]   # creating empty list to store ratings\n",
    "review_list5=[]   # creating empty list to store review summary\n",
    "full_review_list5=[]   # creating empty list to store full review\n",
    "\n",
    "for i in range(0,11):\n",
    "    \n",
    "    #scraping rating \n",
    "    rating_tags5=driver5.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]') # scraping all the tag names where we have ratings\n",
    "    for r in rating_tags5:\n",
    "        rating_list5.append(r.text)  # adding data to the empty list we created\n",
    "    \n",
    "    #scraping review summary \n",
    "    review_tags5=driver5.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]') # scraping all the tag names where we have review summary\n",
    "    for r in review_tags5:\n",
    "        review_list5.append(r.text)  # adding data to the empty list we created\n",
    "        \n",
    "    #scraping full review\n",
    "    full_review_tags5=driver5.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]') # scraping all the tag names where we have full review\n",
    "    for r in full_review_tags5:\n",
    "        full_review_list5.append(r.text.replace('\\n',' ').strip())  # adding data to the empty list we created\n",
    "    \n",
    "    #clicking next button\n",
    "    next_button5=driver5.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "    next_button5.click()  # clicking next button \n",
    "    time.sleep(5)\n",
    "    \n",
    "rating5=rating_list5[0:100]\n",
    "review5=review_list5[0:100]\n",
    "full_review5=full_review_list5[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "e7245e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating5), len(review5), len(full_review5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "51a42c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "cd612719",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  The iPhone 11 of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Amazing Phone üòçüòçüòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Everything is accept the charging Speed is fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Super ncy I love it‚ù§Ô∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Using my first apple product. ~Camera is good,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Loved it!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5    Terrific purchase   \n",
       "96      5              Awesome   \n",
       "97      5               Super!   \n",
       "98      5               Super!   \n",
       "99      5            Just wow!   \n",
       "\n",
       "                                          Full_review  \n",
       "0   The Best Phone for the Money  The iPhone 11 of...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95                                  Amazing Phone üòçüòçüòç  \n",
       "96  Everything is accept the charging Speed is fan...  \n",
       "97                              Super ncy I love it‚ù§Ô∏è  \n",
       "98  Using my first apple product. ~Camera is good,...  \n",
       "99                                         Loved it!!  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making data frame\n",
    "data5={'Rating':rating5,'Review_summary':review5,'Full_review':full_review5}\n",
    "reviews_df=pd.DataFrame(data5)\n",
    "\n",
    "#dataframe\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e623c",
   "metadata": {},
   "source": [
    "========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006dc3af",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "8fa17cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver6 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "8a0aa97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up flipkart.com website on automated chrome window\n",
    "driver6.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "799f4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skippping login\n",
    "skip_login6=driver6.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "skip_login6.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "a3840f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for sneakers\n",
    "search_field_product6=driver6.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search_field_product6.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "74c0dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking search button\n",
    "search_button6=driver6.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_button6.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "5788cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list6=[]   # creating empty list to store brand name\n",
    "product_description6=[]   # creating empty list to store product description\n",
    "price_list6=[]   # creating empty list to store price\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    #scraping brand name\n",
    "    brand_tags6=driver6.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]') # scraping all the tag names hwere we have brand names\n",
    "    for b in brand_tags6:\n",
    "        brand_list6.append(b.text)  # adding data to the empty list we created\n",
    "        \n",
    "    #scraping product description   \n",
    "    product_description_tags6=driver6.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    for p in product_description_tags6:\n",
    "        product_description6.append(p.text)  # adding data to the empty list we created\n",
    "        \n",
    "    #scraping price  \n",
    "    price_tags6=driver6.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for pr in price_tags6:\n",
    "        price_list6.append(pr.text.replace('‚Çπ',''))  # adding data to the empty list we created\n",
    "        \n",
    "    #clicking next button    \n",
    "    next_button6=driver6.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button6.click()  # clicking next button \n",
    "    time.sleep(5)\n",
    "    \n",
    "brands6=brand_list6[0:100]\n",
    "description6=product_description6[0:100]\n",
    "price6=price_list6[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "3a0f422f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brands6),len(description6),len(price6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "cf6f9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "76c130ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price(‚Çπ)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cross Finger</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUNKASTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Kwik FIT casual sneaker shoes and partywear sh...</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>STYLISH MENS BLACK SNEAKER Sneakers For Men</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KWIK FIT</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jumpink</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>Men Black Woven Design Fly Sneakers Sneakers F...</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PEXLO</td>\n",
       "      <td>RS-X Pop Sneakers For Men</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>U.S. POLO ASSN.</td>\n",
       "      <td>Athleisure Sneakers For Men</td>\n",
       "      <td>1,919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AROOTER</td>\n",
       "      <td>WINSP-16 Sneakers For Men</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                                Product_description  \\\n",
       "0      Cross Finger                                   Sneakers For Men   \n",
       "1         DUNKASTON      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "2          URBANBOX  Kwik FIT casual sneaker shoes and partywear sh...   \n",
       "3            BRUTON        STYLISH MENS BLACK SNEAKER Sneakers For Men   \n",
       "4          KWIK FIT                                   Sneakers For Men   \n",
       "..              ...                                                ...   \n",
       "95          Jumpink                                   Sneakers For Men   \n",
       "96            SPARX  Men Black Woven Design Fly Sneakers Sneakers F...   \n",
       "97            PEXLO                          RS-X Pop Sneakers For Men   \n",
       "98  U.S. POLO ASSN.                        Athleisure Sneakers For Men   \n",
       "99          AROOTER                          WINSP-16 Sneakers For Men   \n",
       "\n",
       "   Price(‚Çπ)  \n",
       "0       429  \n",
       "1       399  \n",
       "2       198  \n",
       "3       295  \n",
       "4       399  \n",
       "..      ...  \n",
       "95      399  \n",
       "96      764  \n",
       "97      321  \n",
       "98    1,919  \n",
       "99      549  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making data frame\n",
    "data6={'Brand':brands6,'Product_description':description6,'Price(‚Çπ)':price6}\n",
    "sneakers_df=pd.DataFrame(data6)\n",
    "\n",
    "#dataframe\n",
    "sneakers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1dc798",
   "metadata": {},
   "source": [
    "========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cebcc1",
   "metadata": {},
   "source": [
    "Q7: write a python program to scrape data from the given link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "2f6f429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver7 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "5dd3f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up myntra.com website on automated chrome window\n",
    "driver7.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "9d638175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering price\n",
    "filter_price7=driver7.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label')\n",
    "filter_price7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "16329c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering black colour\n",
    "filter_colour7=driver7.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label')\n",
    "filter_colour7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "ea3f7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list7=[]   # creating empty list to store brand name\n",
    "product_description7=[]   # creating empty list to store product description\n",
    "price_list7=[]   # creating empty list to store price\n",
    "\n",
    "for i in range(0,2):\n",
    "    \n",
    "    #scraping brand name\n",
    "    brand_tags7=driver7.find_elements_by_xpath('//h3[@class=\"product-brand\"]') # scraping all the tag names where we have brand names\n",
    "    for b in brand_tags7:\n",
    "        brand_list7.append(b.text)  # adding data to the empty list we created\n",
    "        \n",
    "    #scraping product description   \n",
    "    product_description_tags7=driver7.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "    for p in product_description_tags7:\n",
    "        product_description7.append(p.text)  # adding data to the empty list we created\n",
    "        \n",
    "    #scraping price    \n",
    "    price_tags7=driver7.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "    for pr in price_tags7:\n",
    "        price_list7.append(pr.text.replace('Rs.',''))  # adding data to the empty list we created\n",
    "        \n",
    "    #clicking next button    \n",
    "    next_button7=driver7.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]')\n",
    "    next_button7.click()  # clicking next button \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "aff33dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand_list7),len(product_description7),len(price_list7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "42e757b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver7.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "2dcab7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short_shoe_description</th>\n",
       "      <th>Price(Rs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>7199 8999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women React MR 3 Running Shoes</td>\n",
       "      <td>8920 10495(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Vantage 2 Running Shoes</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Colourblocked RS-Z Core</td>\n",
       "      <td>7499 9999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Solar Glide 5 Running Shoe</td>\n",
       "      <td>13999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Clarks</td>\n",
       "      <td>Men Leather Derbys</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Solid Loafers</td>\n",
       "      <td>8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Ustraa black</td>\n",
       "      <td>8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Men Textured Formal Leather Loafers</td>\n",
       "      <td>8990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand               Short_shoe_description             Price(Rs)\n",
       "0       Skechers           Men Max Cushioning Running    7199 8999(20% OFF)\n",
       "1           Nike       Women React MR 3 Running Shoes   8920 10495(15% OFF)\n",
       "2           ALDO                         Men Sneakers                  9999\n",
       "3   UNDER ARMOUR          Men Vantage 2 Running Shoes                  7999\n",
       "4           Puma          Men Colourblocked RS-Z Core    7499 9999(25% OFF)\n",
       "..           ...                                  ...                   ...\n",
       "95        ADIDAS       Men Solar Glide 5 Running Shoe                 13999\n",
       "96        Clarks                   Men Leather Derbys                  9999\n",
       "97     J.FONTINI                    Men Solid Loafers                  8990\n",
       "98      DAVINCHI                         Ustraa black                  8990\n",
       "99      DAVINCHI  Men Textured Formal Leather Loafers                  8990\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making data frame\n",
    "data7={'Brand':brand_list7,'Short_shoe_description':product_description7,'Price(Rs)':price_list7}\n",
    "shoe_df=pd.DataFrame(data7)\n",
    "\n",
    "#dataframe\n",
    "shoe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5db1950",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8752d",
   "metadata": {},
   "source": [
    "Q8:scrape the data from given link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "64cbb384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver8 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "3f99c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up amazon.com website on automated chrome window\n",
    "driver8.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "0ae7248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering laptops in search box\n",
    "field_search8=driver8.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "field_search8.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "4d0528dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search button\n",
    "search_button8=driver8.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search_button8.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "6b17b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying cpu type filter\n",
    "filter_cpu_type8=driver8.find_element_by_xpath('//li[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span[1]')\n",
    "filter_cpu_type8.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "c9f616e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping title,ratings and price of laptops\n",
    "\n",
    "laptop_title8=[]   # creating empty list to store title\n",
    "title_tags8=driver8.find_elements_by_xpath('//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "for i in title_tags8:\n",
    "    laptop_title8.append(i.text.strip())\n",
    "laptop_name8=laptop_title8[0:10]\n",
    "\n",
    "product_ratings=[]\n",
    "# find ratings box\n",
    "ratings_box = driver8.find_elements_by_xpath('//div[@class=\"a-section a-spacing-none a-spacing-top-micro\"]/div/span')\n",
    "# find ratings and ratings_num\n",
    "for i in ratings_box:\n",
    "    if ratings_box != []:\n",
    "        ratings = ratings_box[0].get_attribute('aria-label')\n",
    "    else:\n",
    "        ratings= 0\n",
    "    product_ratings.append(ratings)\n",
    "ratings8=product_ratings[0:10]\n",
    "\n",
    "price8=[]\n",
    "price_tags8=driver8.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "for p in price_tags8:\n",
    "    price8.append(p.text.replace('‚Çπ','').strip())\n",
    "laptop_price8=price8[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "c0742462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(laptop_name8), len(laptop_rating8), len(laptop_price8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "02cec7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver8.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "bc8c2572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price(‚Çπ)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Predator Helios 300 11th Gen Intel Core i...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>1,69,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSI Modern 14, Intel i7-1195G7, 14\" FHD IPS-Le...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>76,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Ultra 3.2K Resolution Display Inte...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>77,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>57,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>85,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 Ev...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LG Gram 14 Intel Evo 11th Gen Core i7 14 inche...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>85,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LG Gram Intel Evo 11th Gen Core i7 17 inches U...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>93,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3‚Äù FHD ...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>84,590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  Acer Predator Helios 300 11th Gen Intel Core i...  5.0 out of 5 stars   \n",
       "1  MSI Modern 14, Intel i7-1195G7, 14\" FHD IPS-Le...  5.0 out of 5 stars   \n",
       "2  Mi Notebook Ultra 3.2K Resolution Display Inte...  5.0 out of 5 stars   \n",
       "3  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...  5.0 out of 5 stars   \n",
       "4  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...  5.0 out of 5 stars   \n",
       "5  HP Pavilion x360 11th Gen Intel Core i7 14 inc...  5.0 out of 5 stars   \n",
       "6  Samsung Galaxy Book2 Intel 12th Gen core i7 Ev...  5.0 out of 5 stars   \n",
       "7  LG Gram 14 Intel Evo 11th Gen Core i7 14 inche...  5.0 out of 5 stars   \n",
       "8  LG Gram Intel Evo 11th Gen Core i7 17 inches U...  5.0 out of 5 stars   \n",
       "9  Fujitsu UH-X 11th Gen Intel Core i7 13.3‚Äù FHD ...  5.0 out of 5 stars   \n",
       "\n",
       "   Price(‚Çπ)  \n",
       "0  1,69,990  \n",
       "1    76,490  \n",
       "2    77,999  \n",
       "3    57,490  \n",
       "4    89,990  \n",
       "5    85,890  \n",
       "6    79,990  \n",
       "7    85,999  \n",
       "8    93,999  \n",
       "9    84,590  "
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame\n",
    "data8={'Title':laptop_name8,'Ratings':ratings8,'Price(‚Çπ)':laptop_price8}\n",
    "laptops_df=pd.DataFrame(data8)\n",
    "\n",
    "#data frame\n",
    "laptops_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0229d201",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd2efb",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location from https://www.ambitionbox.com/. \n",
    "        You have to scrape company name, \n",
    "        No. of days ago when job was posted, \n",
    "        Rating of the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "b84eaae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver9 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "e4c253d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up ambitionbox.com website on automated chrome window\n",
    "driver9.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "be3a799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on jobs\n",
    "click_jobs9=driver9.find_element_by_xpath('/html/body/div[1]/nav/nav/a[6]')\n",
    "click_jobs9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "948f9288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for job search\n",
    "search_designation9=driver9.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "search_designation9.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "95a40362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search button\n",
    "click_search_button9=driver9.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button')\n",
    "click_search_button9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "b45b61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on location button\n",
    "click_location_button9=driver9.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/p')\n",
    "click_location_button9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "6e33f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search location\n",
    "search_location9=driver9.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "search_location9.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "0ee8a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select location Noida\n",
    "select_noida9=driver9.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/input')\n",
    "select_noida9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "b3b3a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping company name\n",
    "company_name9=[]  # creating empty list to store company name\n",
    "#scraping all the tags where we have company name\n",
    "company_name_tags9=driver9.find_elements_by_xpath('//p[@class=\"company body-medium\"]')\n",
    "for i in company_name_tags9:\n",
    "    company_name9.append(i.text)  # adding data to the empty list\n",
    "\n",
    "#scraping no. of days job was posted\n",
    "days_ago9=[]  # creating empty list to store data\n",
    "# scraping all the tags where we have tags of job posted days ago\n",
    "days_ago_tags9=driver9.find_elements_by_xpath('//span[@class=\"body-small-l\"]')\n",
    "for i in days_ago_tags9:\n",
    "    days_ago9.append(i.text)\n",
    "days9=days_ago9[0::2]\n",
    "\n",
    "#scraping ratings of the company\n",
    "ratings9=[]  # creating empty list to store ratings of the company\n",
    "# scraping all the tags where we have ratings\n",
    "ratings_tags9=driver9.find_elements_by_xpath('//span[@class=\"body-small\"]')\n",
    "for i in ratings_tags9: # iterating the data\n",
    "    ratings9.append(i.text) # adding values top the empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "c03de108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company_name9), len(days9), len(ratings9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "6abbfa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver9.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "fca8ced9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Days_ago_job_posted</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>21d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TECHNIP GLOBAL BUSINESS SERVICES PRIVATE LIMITED</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bristlecone India Limited</td>\n",
       "      <td>16d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zyoin</td>\n",
       "      <td>20d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Newgen Software Technologies Ltd.</td>\n",
       "      <td>22d ago</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JK Technosoft Ltd</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pitney Bowes India Pvt Ltd</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Company_name Days_ago_job_posted  \\\n",
       "0                  EXL Services.com ( I ) Pvt. Ltd.              9d ago   \n",
       "1                     GENPACT India Private Limited             21d ago   \n",
       "2  TECHNIP GLOBAL BUSINESS SERVICES PRIVATE LIMITED              7d ago   \n",
       "3                     GENPACT India Private Limited            1mon ago   \n",
       "4                         Bristlecone India Limited             16d ago   \n",
       "5                                             Zyoin             20d ago   \n",
       "6                Ashkom Media India Private Limited              7d ago   \n",
       "7                 Newgen Software Technologies Ltd.             22d ago   \n",
       "8                                 JK Technosoft Ltd            1mon ago   \n",
       "9                        Pitney Bowes India Pvt Ltd            1mon ago   \n",
       "\n",
       "  Ratings  \n",
       "0     3.9  \n",
       "1     4.0  \n",
       "2     3.9  \n",
       "3     4.0  \n",
       "4     3.8  \n",
       "5     4.1  \n",
       "6     3.7  \n",
       "7     3.5  \n",
       "8     3.7  \n",
       "9     4.2  "
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making dataframe\n",
    "data9={'Company_name':company_name9,'Days_ago_job_posted':days9,'Ratings':ratings9}\n",
    "\n",
    "Datascientist_jobs_df=pd.DataFrame(data9)\n",
    "\n",
    "#dataframe\n",
    "Datascientist_jobs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e75fe29",
   "metadata": {},
   "source": [
    "========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed3d48",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "d8da6630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the webdriver    \n",
    "driver10 = webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "6cd7c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up ambitionbox.com website on automated chrome window\n",
    "driver10.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "c854aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on salaries\n",
    "click_salaries10=driver10.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "click_salaries10.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "2dd57f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements for salaries search\n",
    "search_job_profile10=driver10.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "search_job_profile10.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "322ed6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping company name\n",
    "company_name10=[]  # creating empty list to store company name\n",
    "#scraping all the tags where we have company name\n",
    "company_name_tags10=driver10.find_elements_by_xpath('//div[@class=\"company-info\"]/div/a')\n",
    "for i in company_name_tags10:\n",
    "    company_name10.append(i.text)  # adding data to the empty list\n",
    "    \n",
    "#scraping total salay record\n",
    "number_of_salaries10=[]\n",
    "#lets scrape all the tags where we have salaries tags\n",
    "salaries_tags10=driver10.find_elements_by_xpath('//div[@class=\"company-info\"]/div/span')\n",
    "for i in salaries_tags10:\n",
    "    number_of_salaries10.append(i.text)\n",
    "salaries10=number_of_salaries10[0::2]\n",
    "\n",
    "#scraping average salary\n",
    "average_salary10=[]\n",
    "#lets scrape all the tags where we have average salary\n",
    "average_salary_tags10=driver10.find_elements_by_xpath('//p[@class=\"averageCtc\"]')\n",
    "for i in average_salary_tags10:\n",
    "    average_salary10.append(i.text.replace('‚Çπ',''))\n",
    "\n",
    "#scraping minimum salary\n",
    "min_salary10=[]\n",
    "#lets scarpe all the tags where we have minimum salary\n",
    "min_salary_tags10=driver10.find_elements_by_xpath('//div[@class=\"value body-medium\"]')\n",
    "for i in min_salary_tags10:\n",
    "    min_salary10.append(i.text.replace('‚Çπ',''))\n",
    "minimum_salary10=min_salary10[0::2]\n",
    "\n",
    "#scraping maximum salary\n",
    "max_salary10=[]\n",
    "#lets scarpe all the tags where we have maximum salary\n",
    "max_salary_tags10=driver10.find_elements_by_xpath('//div[@class=\"value body-medium\"]')\n",
    "for i in max_salary_tags10:\n",
    "    max_salary10.append(i.text.replace('‚Çπ',''))\n",
    "maximum_salary10=max_salary10[1::2]\n",
    "\n",
    "#scraping experience required\n",
    "exp_required10=[]\n",
    "#lets scrape all the tags where we have experience required\n",
    "exp_required_tags10=driver10.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]')\n",
    "for i in exp_required_tags10:\n",
    "    exp_required10.append(i.text.replace('Data Scientist\\n . \\n','').replace('exp',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "c6488b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10, 10, 10)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking length of each list\n",
    "len(company_name10), len(salaries10), len(average_salary10), len(minimum_salary10), len(maximum_salary10), len(exp_required10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "be9d437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver10.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "c325e4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Number_of_salaries</th>\n",
       "      <th>Average_salary(‚Çπ)</th>\n",
       "      <th>Minimum_salary(‚Çπ)</th>\n",
       "      <th>Maximum_salary(‚Çπ)</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>29.7L</td>\n",
       "      <td>25.0L</td>\n",
       "      <td>35.0L</td>\n",
       "      <td>3 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 32 salaries</td>\n",
       "      <td>20.5L</td>\n",
       "      <td>15.0L</td>\n",
       "      <td>25.5L</td>\n",
       "      <td>3-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>18.9L</td>\n",
       "      <td>5.6L</td>\n",
       "      <td>26.2L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "      <td>15.9L</td>\n",
       "      <td>9.8L</td>\n",
       "      <td>20.0L</td>\n",
       "      <td>2 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 27 salaries</td>\n",
       "      <td>15.2L</td>\n",
       "      <td>11.0L</td>\n",
       "      <td>22.0L</td>\n",
       "      <td>3-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 81 salaries</td>\n",
       "      <td>15.2L</td>\n",
       "      <td>9.5L</td>\n",
       "      <td>22.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 46 salaries</td>\n",
       "      <td>14.8L</td>\n",
       "      <td>9.0L</td>\n",
       "      <td>20.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 53 salaries</td>\n",
       "      <td>14.0L</td>\n",
       "      <td>8.3L</td>\n",
       "      <td>20.5L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>12.7L</td>\n",
       "      <td>10.0L</td>\n",
       "      <td>21.0L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>12.4L</td>\n",
       "      <td>8.5L</td>\n",
       "      <td>15.0L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company_name    Number_of_salaries Average_salary(‚Çπ)  \\\n",
       "0                   Walmart  based on 11 salaries             29.7L   \n",
       "1                  Ab Inbev  based on 32 salaries             20.5L   \n",
       "2              Reliance Jio  based on 10 salaries             18.9L   \n",
       "3                        ZS  based on 15 salaries             15.9L   \n",
       "4                     Optum  based on 27 salaries             15.2L   \n",
       "5         Fractal Analytics  based on 81 salaries             15.2L   \n",
       "6           Tiger Analytics  based on 46 salaries             14.8L   \n",
       "7              UnitedHealth  based on 53 salaries             14.0L   \n",
       "8                   Verizon  based on 14 salaries             12.7L   \n",
       "9  Ganit Business Solutions  based on 13 salaries             12.4L   \n",
       "\n",
       "  Minimum_salary(‚Çπ) Maximum_salary(‚Çπ) Experience_required  \n",
       "0             25.0L             35.0L              3 yrs   \n",
       "1             15.0L             25.5L            3-4 yrs   \n",
       "2              5.6L             26.2L              4 yrs   \n",
       "3              9.8L             20.0L              2 yrs   \n",
       "4             11.0L             22.0L            3-4 yrs   \n",
       "5              9.5L             22.0L            2-4 yrs   \n",
       "6              9.0L             20.0L            2-4 yrs   \n",
       "7              8.3L             20.5L            2-4 yrs   \n",
       "8             10.0L             21.0L              4 yrs   \n",
       "9              8.5L             15.0L              4 yrs   "
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making dataframe\n",
    "data10={'Company_name':company_name10,'Number_of_salaries':salaries10,'Average_salary(‚Çπ)':average_salary10,'Minimum_salary(‚Çπ)':minimum_salary10,'Maximum_salary(‚Çπ)':maximum_salary10,'Experience_required':exp_required10}\n",
    "Salaries_df = pd.DataFrame(data10)\n",
    "\n",
    "#dataframe\n",
    "Salaries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d10069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
